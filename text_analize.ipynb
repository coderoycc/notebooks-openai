{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "4e614c41",
        "JNECz625SYXP",
        "eb928f24"
      ],
      "authorship_tag": "ABX9TyPSDg0tfBPdTFwFuhVvlCGP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/coderoycc/notebooks-openai/blob/main/text_analize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff271fb7"
      },
      "source": [
        "## Cargar API key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "498a4c4d"
      },
      "source": [
        "OPENAI_API_KEY = input(\"Please enter your OpenAI API key: \")\n",
        "print(\"OpenAI API key loaded.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78dd8a52"
      },
      "source": [
        "## Inicializar cliente openai"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "074cd782",
        "outputId": "258bf696-093f-40f1-f4f1-176d621a24ca"
      },
      "source": [
        "import openai\n",
        "\n",
        "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "print(\"OpenAI client initialized.\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OpenAI client initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb117783"
      },
      "source": [
        "## Explicación de comparación de texto con openai embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e614c41"
      },
      "source": [
        "### Análisis de Similitud de Texto con Embeddings de OpenAI\n",
        "\n",
        "Los embeddings de texto son representaciones numéricas vectoriales (listas de números) que capturan el significado semántico de una palabra, frase o documento. Textos con significados similares se mapean a vectores que están cerca uno del otro en un espacio de alta dimensión.\n",
        "\n",
        "Para analizar la similitud entre dos textos, se pueden seguir estos pasos:\n",
        "1. **Obtener Embeddings:** Utilizar un modelo de embedding para generar el vector numérico para cada texto.\n",
        "2. **Calcular Similitud:** Calcular la similitud entre los vectores resultantes. Una métrica común es la **similitud del coseno**, que mide el coseno del ángulo entre dos vectores. Un valor cercano a 1 indica alta similitud, mientras que un valor cercano a 0 (o negativo) indica baja similitud.\n",
        "\n",
        "Los modelos de embedding de OpenAI son adecuados para esta tarea porque han sido entrenados en vastos conjuntos de datos de texto, lo que les permite generar embeddings de alta calidad que capturan relaciones semánticas complejas.\n",
        "\n",
        "**Modelo Recomendado para su Caso de Uso:**\n",
        "\n",
        "Para comparar la similitud de frases cortas o descripciones de productos como \"Cepillo de dientes 3mm cerdas flexibles\" y \"Dentista\", el modelo `text-embedding-ada-002` es una excelente opción.\n",
        "\n",
        "**¿Por qué `text-embedding-ada-002` es óptimo?**\n",
        "\n",
        "*   **Calidad del Embedding:** Este modelo genera embeddings de alta dimensión que son muy efectivos para capturar matices semánticos, incluso en frases cortas. Esto es crucial para distinguir entre conceptos relacionados pero distintos.\n",
        "*   **Eficiencia y Costo:** `text-embedding-ada-002` ofrece un buen equilibrio entre la calidad del embedding, la velocidad de procesamiento y el costo, lo que lo hace ideal para aplicaciones prácticas y de mayor escala.\n",
        "*   **Casos de Uso Similares:** Ha demostrado un rendimiento sólido en una amplia gama de tareas de similitud de texto, incluyendo la comparación de términos y descripciones en contextos de búsqueda y recomendación.\n",
        "\n",
        "Al utilizar `text-embedding-ada-002` y calcular la similitud del coseno entre los embeddings de \"Cepillo de dientes 3mm cerdas flexibles\" y \"Dentista\", se obtendrá una puntuación numérica que indica cuán semánticamente similares son estas frases según el modelo. Esperaríamos una puntuación de similitud baja, ya que los conceptos son bastante diferentes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "acc5b436",
        "outputId": "4e96b671-3470-4f2d-a867-bd7e1938379d"
      },
      "source": [
        "texts = [\n",
        "    \"Cepillo de dientes 3mm cerdas flexibles\",\n",
        "    \"Dentista\",\n",
        "    \"Este es el primer texto.\",\n",
        "    \"Este es el segundo texto, muy similar al primero.\",\n",
        "    \"Una frase completamente diferente sobre coches.\"\n",
        "]\n",
        "\n",
        "# Get embeddings using the OpenAI client\n",
        "response = client.embeddings.create(\n",
        "    input=texts,\n",
        "    model=\"text-embedding-ada-002\"\n",
        ")\n",
        "\n",
        "# Extract the embedding vectors from the response\n",
        "embeddings = [data.embedding for data in response.data]\n",
        "\n",
        "print(f\"Generated {len(embeddings)} embeddings.\")\n",
        "print(f\"Shape of the first embedding: {len(embeddings[0])}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated 5 embeddings.\n",
            "Shape of the first embedding: 1536\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cálculo del coseno"
      ],
      "metadata": {
        "id": "JNECz625SYXP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "31ba8645",
        "outputId": "8c1f7038-322f-4fc8-c975-6e65132a370d"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Convert the list of embeddings to a NumPy array\n",
        "embeddings_array = np.array(embeddings)\n",
        "\n",
        "# Calculate the cosine similarity matrix\n",
        "similarity_matrix = cosine_similarity(embeddings_array)\n",
        "\n",
        "print(\"Cosine similarity matrix calculated.\")\n",
        "print(similarity_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cosine similarity matrix calculated.\n",
            "[[1.         0.82850072 0.73061055 0.72918274 0.75368885]\n",
            " [0.82850072 1.         0.74835752 0.74004313 0.75264993]\n",
            " [0.73061055 0.74835752 1.         0.89784768 0.8104893 ]\n",
            " [0.72918274 0.74004313 0.89784768 1.         0.81662499]\n",
            " [0.75368885 0.75264993 0.8104893  0.81662499 1.        ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb928f24"
      },
      "source": [
        "## Proporcionar ejemplos explicativos.\n",
        "\n",
        "Ejemplos que demuestren el análisis de similitud de textos con explicaciones de los resultados en español."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdc21d60"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "texts = [\n",
        "    \"Cepillo de dientes 3mm cerdas flexibles\",\n",
        "    \"Dentista\",\n",
        "    \"Este es el primer texto.\",\n",
        "    \"Este es el segundo texto, muy similar al primero.\",\n",
        "    \"Una frase completamente diferente sobre coches.\"\n",
        "]\n",
        "\n",
        "# Assuming 'similarity_matrix' and 'texts' are available from previous steps\n",
        "\n",
        "print(\"### Resultados del Análisis de Similitud de Texto\\n\")\n",
        "\n",
        "for i in range(len(texts)):\n",
        "    for j in range(i + 1, len(texts)):\n",
        "        text1 = texts[i]\n",
        "        text2 = texts[j]\n",
        "        similarity_score = similarity_matrix[i, j]\n",
        "\n",
        "        print(f\"**Textos:**\\n- \\\"{text1}\\\"\\n- \\\"{text2}\\\"\")\n",
        "        print(f\"**Similitud del Coseno:** {similarity_score:.4f}\")\n",
        "\n",
        "        # Explanation based on similarity score\n",
        "        if similarity_score > 0.7:\n",
        "            explanation = \"Estos textos son muy similares semánticamente.\"\n",
        "        elif similarity_score > 0.4:\n",
        "            explanation = \"Estos textos tienen cierta similitud semántica.\"\n",
        "        elif similarity_score > 0.1:\n",
        "             explanation = \"Estos textos tienen baja similitud semántica.\"\n",
        "        else:\n",
        "            explanation = \"Estos textos son semánticamente muy diferentes.\"\n",
        "\n",
        "        # Specific explanation for \"Cepillo de dientes 3mm cerdas flexibles\" vs \"Dentista\"\n",
        "        if (text1 == \"Cepillo de dientes 3mm cerdas flexibles\" and text2 == \"Dentista\") or \\\n",
        "           (text1 == \"Dentista\" and text2 == \"Cepillo de dientes 3mm cerdas flexibles\"):\n",
        "            explanation += \" En este caso particular, la baja similitud indica que, según el modelo, un cepillo de dientes y un dentista son conceptos semánticamente distintos, lo cual es esperado.\"\n",
        "\n",
        "\n",
        "        print(f\"**Explicación:** {explanation}\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ejemplo real usando chatgpt embeddings"
      ],
      "metadata": {
        "id": "EMn67CKJPfCd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorias = {\n",
        "    \"Dispositivos y Artículos Médicos\": \"OTROS ARTÍCULOS PARA FINES MÉDICOS O QUIRÚRGICOS\",\n",
        "    \"Fármacos\": \"PRODUCTOS FARMACÉUTICOS\",\n",
        "    \"Fármacos y Medicina Veterinaria\": \"PRODUCTOS FARMACÉUTICOS, MEDICINALES Y VETERINARIOS\",\n",
        "    \"Medicamentos Terapéuticos\": \"MEDICAMENTOS PARA USOS TERAPÉUTICOS O PROFILÁCTICOS\",\n",
        "    \"Fármacos, Veterinaria y Cosméticos\": \"PRODUCTOS FARMACÉUTICOS, MEDICINALES, VETERINARIOS, COSMÉTICOS Y ARTÍCULOS DE TOCADOR\",\n",
        "    \"Venta al por Menor de Limpieza\": \"SERVICIOS DE COMERCIO AL POR MENOR DE MATERIALES DE LIMPIEZA EN TIENDAS ESPECIALIZADAS\",\n",
        "    \"Venta al por Menor de Cosméticos y Tocador\": \"SERVICIOS DE COMERCIO AL POR MENOR DE ARTÍCULOS DE PERFUMERÍA, COSMÉTICOS Y JABONES DE TOCADOR EN TIENDAS ESPECIALIZADAS\",\n",
        "    \"Artículos de Limpieza Especializados\": \"OTROS PRODUCTOS DE LIMPIEZA ESPECIALIZADOS EN TIENDAS\",\n",
        "    \"Indefinido\": \"\",\n",
        "}\n",
        "productos = [\"COMPRESA 10 CM X 10 CM\",\n",
        "\"INTIBON GEL 150 ML\",\n",
        "\"ACETILCISTEINA 200 MG COF\",\n",
        "\"ACTILAB COMPRIMIDO\",\n",
        "\"SUCRASTEVIA 150\",\n",
        "\"INDOLAB SUP ADULTO\",\n",
        "\"ALCODERM 10 G\",\n",
        "\"ALCOLAX COMP\",\n",
        "\"CLAUSIMUS\",\n",
        "\"CEPILLO TWISTER  MEDIO X 2\",\n",
        "\"ALERGIN COMP\",\n",
        "\"AZITROALCOS 200 MG SUSP\",\n",
        "\"BEBIDOL JARABE\",\n",
        "\"CALMADOLCITO\",\n",
        "\"PVM SIN LACTOSA CHOCOLATE\",\n",
        "\"CLINDALCOS CREMA\",\n",
        "\"CREMA DE ALMENDRAS 24 G\",\n",
        "\"CURADIL 75 250 ML\",\n",
        "\"LEVOALCOS IV 500 MG 100 ML\",\n",
        "\"LEVOALCOS 500 MG COMP\",\"COCHE A CONTROL REMOTO\"]"
      ],
      "metadata": {
        "id": "pwQE4X-2P9G7"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Definición de funciones para procesar datos"
      ],
      "metadata": {
        "id": "fY97yV6JQFMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def embed_text(text: str):\n",
        "  resp = client.embeddings.create(\n",
        "    model=\"text-embedding-3-small\",\n",
        "    input=[text]\n",
        "  )\n",
        "  # print(resp.data[0].embedding)\n",
        "  return resp.data[0].embedding\n",
        "\n",
        "def cosine_similarity(a: np.ndarray, b: np.ndarray):\n",
        "  return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
      ],
      "metadata": {
        "id": "sE5UTUhEVNxc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats_embeds = {category: embed_text(category) for category in categorias.keys() }"
      ],
      "metadata": {
        "id": "TwmmLnNDVncZ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify(prodName: str):\n",
        "  emb = embed_text(prodName)\n",
        "  # calcular similitudes con las categorias\n",
        "  similitudes = { category: cosine_similarity(np.array(emb), np.array(c_emb)) for category, c_emb in cats_embeds.items() }\n",
        "\n",
        "  mayorAprox = max(similitudes, key=similitudes.get)\n",
        "  return mayorAprox"
      ],
      "metadata": {
        "id": "unt87GnIc8UD"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_productos = {producto: classify(producto) for producto in productos}"
      ],
      "metadata": {
        "id": "ecghY-xldrIT"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_productos"
      ],
      "metadata": {
        "id": "UUXtQx7beMZ-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}